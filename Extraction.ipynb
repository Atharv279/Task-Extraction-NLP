{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Person</th>\n",
       "      <th>Action</th>\n",
       "      <th>Deadline</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jake must call the plumber before noon</td>\n",
       "      <td>Jake</td>\n",
       "      <td>call</td>\n",
       "      <td>before noon</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emma should finish reading the research paper</td>\n",
       "      <td>Emma</td>\n",
       "      <td>finish</td>\n",
       "      <td>None</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tom needs to prepare for his upcoming job inte...</td>\n",
       "      <td>Tom</td>\n",
       "      <td>prepare</td>\n",
       "      <td>None</td>\n",
       "      <td>Work</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Task Person   Action  \\\n",
       "0             Jake must call the plumber before noon   Jake     call   \n",
       "1      Emma should finish reading the research paper   Emma   finish   \n",
       "2  Tom needs to prepare for his upcoming job inte...    Tom  prepare   \n",
       "\n",
       "      Deadline Category  \n",
       "0  before noon    Other  \n",
       "1         None    Other  \n",
       "2         None     Work  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "\n",
    "# Download required NLTK datasets\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define predefined task categories\n",
    "CATEGORY_WORDS = {\n",
    "    \"Shopping\": [\"buy\", \"purchase\", \"order\", \"pick\"],\n",
    "    \"Work\": [\"submit\", \"send\", \"email\", \"schedule\", \"prepare\", \"review\", \"discuss\"],\n",
    "    \"Household\": [\"clean\", \"wash\", \"arrange\", \"organize\", \"fix\"],\n",
    "    \"Education\": [\"study\", \"attend\", \"read\", \"write\", \"review\"],\n",
    "    \"Finance\": [\"pay\", \"deposit\", \"withdraw\", \"invest\", \"transfer\"]\n",
    "}\n",
    "\n",
    "TASK_KEYWORDS = {\"has to\", \"should\", \"must\", \"needs to\", \"is required to\"}\n",
    "DEADLINE_INDICATORS = {\"by\", \"before\", \"at\", \"on\", \"until\"}\n",
    "TIME_KEYWORDS = {\"tomorrow\", \"next\", \"today\", \"morning\", \"afternoon\", \"evening\", \"pm\", \"am\",\n",
    "                 \"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\", \"saturday\", \"sunday\"}\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Step 1: Preprocessing\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Clean text by removing stop words, punctuation, and tokenizing into sentences.\"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    cleaned_sentences = []\n",
    "\n",
    "    for sent in sentences:\n",
    "        sent = re.sub(r\"[^\\w\\s]\", \"\", sent.strip())  # Remove punctuation\n",
    "        words = word_tokenize(sent)\n",
    "        cleaned_sentences.append(\" \".join(words))\n",
    "\n",
    "    return cleaned_sentences\n",
    "\n",
    "# Step 2: Identify Task Sentences\n",
    "def identify_tasks(sentences):\n",
    "    \"\"\"Identify sentences that represent actionable tasks based on heuristics.\"\"\"\n",
    "    actionable_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence)\n",
    "        pos_tags = nltk.pos_tag(words)\n",
    "\n",
    "        if pos_tags and (pos_tags[0][1] == \"VB\" or \n",
    "                         (pos_tags[0][1] in [\"MD\", \"VB\"] and len(pos_tags) > 1 and pos_tags[1][1].startswith(\"VB\"))):\n",
    "            actionable_sentences.append(sentence)\n",
    "            continue\n",
    "        \n",
    "        if any(keyword in sentence.lower() for keyword in TASK_KEYWORDS):\n",
    "            actionable_sentences.append(sentence)\n",
    "            continue\n",
    "\n",
    "    return actionable_sentences\n",
    "\n",
    "# Step 3: Extract Entities\n",
    "def extract_person(words, pos_tags):\n",
    "    \"\"\"Extract the responsible person from a sentence using POS tagging.\"\"\"\n",
    "    for i, (word, tag) in enumerate(pos_tags):\n",
    "        if tag == \"NNP\":  # Proper noun (Name)\n",
    "            return word\n",
    "        if i == 0 and word[0].isupper() and word.lower() not in TIME_KEYWORDS:\n",
    "            return word\n",
    "    return None  \n",
    "\n",
    "def extract_action(words, pos_tags):\n",
    "    \"\"\"Extract the main action verb from a sentence.\"\"\"\n",
    "    for word, tag in pos_tags:\n",
    "        if tag.startswith(\"VB\") and word.lower() not in [\"has\", \"needs\", \"must\", \"should\"]:  \n",
    "            return word\n",
    "    return None\n",
    "\n",
    "def extract_deadline(words):\n",
    "    \"\"\"Extract deadline from a sentence based on time-related words.\"\"\"\n",
    "    for i, word in enumerate(words):\n",
    "        if word in DEADLINE_INDICATORS and i + 1 < len(words):\n",
    "            return \" \".join(words[i:i+2])  \n",
    "        if word in TIME_KEYWORDS:\n",
    "            return word.capitalize()  \n",
    "    return None\n",
    "\n",
    "def categorize_task(action):\n",
    "    \"\"\"Categorize a task based on predefined category words.\"\"\"\n",
    "    for category, words in CATEGORY_WORDS.items():\n",
    "        if action in words:  # If action matches a category word\n",
    "            return category\n",
    "    return \"Other\"  \n",
    "\n",
    "def extract_entities(sentence):\n",
    "    \"\"\"Extract structured details from a task sentence.\"\"\"\n",
    "    words = word_tokenize(sentence)\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "\n",
    "    person = extract_person(words, pos_tags)  # Extract person\n",
    "    action = extract_action(words, pos_tags)  # Extract action\n",
    "    deadline = extract_deadline(words)  # Extract deadline\n",
    "    category = categorize_task(action)  # Categorize task\n",
    "\n",
    "    return {\"Task\": sentence, \"Person\": person, \"Action\": action, \"Deadline\": deadline, \"Category\": category}\n",
    "\n",
    "# Sample Input\n",
    "text = \"\"\"David needs to submit the quarterly financial report by Monday. \n",
    "Sarah should clean the living room before the guests arrive. \n",
    "Alex must send the project proposal to the manager. \n",
    "John wants to buy a new laptop tomorrow. \n",
    "Emma is planning a vacation next week.\"\"\"\n",
    "\n",
    "# Step 1: Preprocess text\n",
    "clean_sentences = preprocess_text(text)\n",
    "\n",
    "# Step 2: Identify tasks\n",
    "tasks = identify_tasks(clean_sentences)\n",
    "\n",
    "# Step 3: Extract and display tasks\n",
    "extracted_tasks = [extract_entities(task) for task in tasks]\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "df = pd.DataFrame(extracted_tasks)\n",
    "\n",
    "# Display structured results\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
